name: Run Base Data Pipelines

on:
  workflow_dispatch:
    inputs:
      pipeline:
        description: 'Pipeline to run (empty = all base pipelines)'
        type: choice
        options:
          - ''
          - 'emotion'
          - 'fashion-mnist'
          - 'wine-quality'
          - 'opencloudhub-readmes-download'
        default: ''
      bump_type:
        type: choice
        options: ['patch', 'minor', 'major']
        default: 'patch'
  schedule:
    - cron: '0 2 * * *'

jobs:
  run-pipelines:
    name: ðŸ”„ Run Data Pipelines
    runs-on: self-hosted-local
    outputs:
      readmes_tag: ${{ steps.get-tag.outputs.readmes_tag }}

    steps:
      - uses: actions/checkout@v4

      - name: ðŸ”§ Install kubectl
        run: |
          if [ ! -f ~/.local/bin/kubectl ]; then
            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x kubectl
            mkdir -p ~/.local/bin
            mv kubectl ~/.local/bin/
          fi
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: ðŸ” Configure kubectl
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > ~/.kube/config
          kubectl cluster-info

      - name: ðŸš€ Run pipeline(s)
        run: |
          PIPELINE="${{ inputs.pipeline }}"
          BUMP_TYPE="${{ inputs.bump_type || 'patch' }}"
          IS_CRON="${{ github.event_name == 'schedule' }}"
          
          if [ -n "$PIPELINE" ]; then
            CMD="dvc repro pipelines/${PIPELINE}/dvc.yaml"
          else
            CMD="bash scripts/run-all-base.sh"
          fi

          cat <<EOF | kubectl apply -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            generateName: data-pipeline-
            namespace: mlops
          spec:
            ttlSecondsAfterFinished: 600
            template:
              spec:
                restartPolicy: Never
                containers:
                  - name: pipeline
                    image: opencloudhuborg/data-registry-pipelines:latest
                    command: ["bash", "-c"]
                    args:
                      - |
                        dvc remote modify minio endpointurl \$AWS_ENDPOINT_URL
                        dvc remote modify minio access_key_id \$AWS_ACCESS_KEY_ID
                        dvc remote modify minio secret_access_key \$AWS_SECRET_ACCESS_KEY
                        ${CMD}
                    env:
                      - name: AWS_ACCESS_KEY_ID
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: accesskey
                      - name: AWS_SECRET_ACCESS_KEY
                        valueFrom:
                          secretKeyRef:
                            name: minio-tenant-secret
                            key: secretkey
                      - name: AWS_ENDPOINT_URL
                        value: "https://minio-api.internal.opencloudhub.org"
                      - name: BUMP_TYPE
                        value: "${BUMP_TYPE}"
                      - name: IS_CRON
                        value: "${IS_CRON}"
                    resources:
                      requests:
                        cpu: "500m"
                        memory: "1Gi"
                      limits:
                        cpu: "2"
                        memory: "4Gi"
          EOF

          sleep 3
          JOB_NAME=$(kubectl get jobs -n mlops --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.name}')
          echo "ðŸ“‹ Job: $JOB_NAME"

          kubectl wait --for=condition=complete --timeout=30m job/$JOB_NAME -n mlops || {
            echo "âŒ Job failed"
            kubectl logs -n mlops job/$JOB_NAME --tail=100
            exit 1
          }

          echo "âœ… Pipeline complete"
          kubectl logs -n mlops job/$JOB_NAME --tail=50

      - name: ðŸ“¥ Get tags from job output
        id: get-tag
        run: |
          # Tags were created inside the container but not pushed yet
          # We need to check what the latest tag would be
          READMES_TAG=$(git tag -l "opencloudhub-readmes-v*" --sort=-version:refname | head -n1)
          echo "readmes_tag=$READMES_TAG" >> $GITHUB_OUTPUT

      - name: ðŸ’¾ Commit and push
        run: |
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'
          git add .
          git commit -m "chore: update datasets [skip ci]" || echo "No changes"
          git push || echo "Nothing to push"
          git push --tags || echo "No tags"

  trigger-embeddings:
    name: ðŸ§  Trigger Embeddings
    needs: run-pipelines
    if: needs.run-pipelines.outputs.readmes_tag != ''
    uses: ./.github/workflows/run-embeddings-pipeline.yaml
    with:
      data_version: ${{ needs.run-pipelines.outputs.readmes_tag }}
    secrets: inherit