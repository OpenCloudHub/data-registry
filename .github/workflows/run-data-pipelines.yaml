name: Run Data Pipelines

on:
  workflow_dispatch:
    inputs:
      pipelines:
        description: 'Pipelines to run (comma-separated)'
        default: 'opencloudhub-readmes-download,wine-quality,fashion-mnist'
        type: string
      force:
        description: 'Force re-run (ignore DVC cache)'
        type: boolean
        default: false
      bump_type:
        description: 'Version bump type'
        type: choice
        options: ['patch', 'minor', 'major']
        default: 'patch'
      is_automated:
        description: 'Mark as automated run (adds -automated suffix to tags)'
        type: boolean
        default: false
      compute_type:
        description: 'Compute configuration'
        required: true
        type: choice
        options:
          - 'cpu-small'
          - 'cpu-medium'
          - 'cpu-large'
          - 'gpu-small'
          - 'gpu-medium'
          - 'gpu-large'
        default: 'cpu-small'
  schedule:
    - cron: '0 2 * * *'

jobs:
  submit:
    name: ðŸš€ Submit Data Pipeline
    runs-on: arc-runner-set
    steps:
      # =========================================================================
      # Setup
      # =========================================================================
      - name: ðŸ”§ Setup kubectl
        uses: OpenCloudHub/.github/.github/actions/setup-kubectl@main
        with:
          kube-config: ${{ secrets.KUBE_CONFIG }}

      # =========================================================================
      # Convert pipelines to JSON array
      # =========================================================================
      - name: ðŸ“ Prepare parameters
        id: params
        run: |
          # Convert comma-separated to JSON array
          # "a,b,c" -> '["a","b","c"]'
          PIPELINES="${{ inputs.pipelines || 'opencloudhub-readmes-download' }}"
          JSON_ARRAY=$(echo "$PIPELINES" | tr ',' '\n' | sed 's/^/"/;s/$/"/' | tr '\n' ',' | sed 's/,$//' | sed 's/^/[/;s/$/]/')
          echo "pipelines_json=${JSON_ARRAY}" >> $GITHUB_OUTPUT
          echo "ðŸ“¦ Pipelines: ${JSON_ARRAY}"

          # For scheduled runs, mark as automated
          IS_AUTOMATED="${{ inputs.is_automated || 'false' }}"
          if [ "${{ github.event_name }}" = "schedule" ]; then
            IS_AUTOMATED="true"
          fi
          echo "is_automated=${IS_AUTOMATED}" >> $GITHUB_OUTPUT

      # =========================================================================
      # Submit workflow
      # =========================================================================
      - name: ðŸš€ Submit Argo Workflow
        id: submit
        run: |
          cat <<EOF | kubectl create -n mlops -f -
          apiVersion: argoproj.io/v1alpha1
          kind: Workflow
          metadata:
            generateName: data-pipeline-
            labels:
              repo: ${{ github.event.repository.name }}
              run-id: "${{ github.run_id }}"
              trigger: "github-actions"
          spec:
            serviceAccountName: workflow-executor
            workflowTemplateRef:
              name: data-pipeline
            arguments:
              parameters:
              - name: pipelines
                value: '${{ steps.params.outputs.pipelines_json }}'
              - name: force
                value: "${{ inputs.force || 'false' }}"
              - name: bump_type
                value: "${{ inputs.bump_type || 'patch' }}"
              - name: is_automated
                value: "${{ steps.params.outputs.is_automated }}"
              - name: compute_type
                value: "${{inputs.compute_type}}"
          EOF

          # Get the actual workflow name
          sleep 2
          ACTUAL_NAME=$(kubectl get workflows -n mlops -l repo=${{ github.event.repository.name }},run-id=${{ github.run_id }} -o jsonpath='{.items[0].metadata.name}')
          echo "workflow_name=${ACTUAL_NAME}" >> $GITHUB_OUTPUT

      # =========================================================================
      # Summary
      # =========================================================================
      - name: ðŸ“Š Summary
        run: |
          WORKFLOW_NAME=${{ steps.submit.outputs.workflow_name }}

          echo "========================================="
          echo "ðŸš€ DATA PIPELINE SUBMITTED"
          echo "========================================="
          echo ""
          echo "Workflow:     ${WORKFLOW_NAME}"
          echo "Pipelines:    ${{ steps.params.outputs.pipelines_json }}"
          echo "Force:        ${{ inputs.force || 'false' }}"
          echo "Bump Type:    ${{ inputs.bump_type || 'patch' }}"
          echo "Compute:      ${{ inputs.compute_type || 'cpu-small' }}"
          echo "Automated:    ${{ steps.params.outputs.is_automated }}"
          echo ""
          echo "ðŸ“Š MONITORING:"
          echo "  https://argo-workflows.internal.opencloudhub.org/workflows/mlops/${WORKFLOW_NAME}"
          echo "========================================="

          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## ðŸš€ Data Pipeline Submitted

          | Parameter | Value |
          |-----------|-------|
          | **Workflow** | \`${WORKFLOW_NAME}\` |
          | **Pipelines** | \`${{ steps.params.outputs.pipelines_json }}\` |
          | **Force** | \`${{ inputs.force || 'false' }}\` |
          | **Bump Type** | \`${{ inputs.bump_type || 'patch' }}\` |
          | **Compute** | \`${{ inputs.compute_type || 'cpu-small' }}\` |
          | **Automated** | \`${{ steps.params.outputs.is_automated }}\` |

          ### ðŸ“Š Monitoring

          - [Argo Workflow](https://argo-workflows.internal.opencloudhub.org/workflows/mlops/${WORKFLOW_NAME})
          EOF
